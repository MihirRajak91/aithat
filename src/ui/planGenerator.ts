import * as vscode from 'vscode';
import { RecentTicket, LLMResponse } from '../types';
import { OllamaProvider } from '../llm/ollama';
import { ContextBuilder } from '../contextBuilder';
import { StreamingPanel } from './streamingPanel';

export class PlanGenerator {
  private contextBuilder: ContextBuilder;
  private outputChannel: vscode.OutputChannel;

  constructor() {
    this.contextBuilder = new ContextBuilder();
    this.outputChannel = vscode.window.createOutputChannel('AI Plan');
  }

  async generatePlan(ticket: RecentTicket): Promise<void> {
    try {
      // Show progress
      await vscode.window.withProgress({
        location: vscode.ProgressLocation.Notification,
        title: 'Generating implementation plan...',
        cancellable: false
      }, async (progress) => {
        progress.report({ message: 'Building workspace context...' });
        
        // Build workspace context
        const context = await this.contextBuilder.buildContext();
        
        progress.report({ message: 'Generating plan with AI...' });
        
        // Initialize Ollama provider (local AI)
        const ollamaProvider = new OllamaProvider({
          model: 'llama2:13b'
        });
        
        // Format prompt
        const prompt = this.formatPrompt(ticket, context);
        
        // Stream plan into a webview panel styled like a chat window
        await this.displayStreaming(ticket, async (append) => {
          await ollamaProvider.streamGeneratePlan(prompt, (token) => {
            append(token);
          });
        });
      });

    } catch (error) {
      console.error('Error generating plan:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      await vscode.window.showErrorMessage(`Failed to generate plan: ${errorMessage}`);
    }
  }

  private formatPrompt(ticket: RecentTicket, context: string): string {
    return `Ticket: ${ticket.key} â€“ ${ticket.summary}
${ticket.description}
---  
Workspace context:
${context}
---  
Return a concise, numbered checklist to implement this ticket. Include specific steps, file modifications, and any new files that need to be created.`;
  }

  private async displayPlan(ticket: RecentTicket, planContent: string): Promise<void> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const fileName = `plan-${ticket.key}-${timestamp}.md`;
    
    const fullContent = `# Implementation Plan for ${ticket.key}

**Ticket:** ${ticket.key} - ${ticket.summary}
**Generated:** ${new Date().toLocaleString()}
**Provider:** ${ticket.provider}

## Plan

${planContent}

---
*Generated by AI Plan VS Code Extension*
`;

    // Create and open the document
    const document = await vscode.workspace.openTextDocument({
      content: fullContent,
      language: 'markdown'
    });

    const editor = await vscode.window.showTextDocument(document);
    
    // Show success message
    await vscode.window.showInformationMessage(`Plan generated for ${ticket.key}!`);
  }

  async selectLLMProvider(): Promise<string> {
    const providers = [
      { label: 'Ollama (Local)', value: 'ollama' },
      { label: 'OpenRouter (Cloud)', value: 'openrouter' }
    ];

    const selected = await vscode.window.showQuickPick(providers, {
      placeHolder: 'Select AI provider for plan generation...'
    });

    return selected?.value || 'ollama';
  }

  async configureLLMProvider(provider: string): Promise<any> {
    if (provider === 'ollama') {
      // Check if Ollama is running
      const ollamaProvider = new OllamaProvider({});
      const isValid = await ollamaProvider.validateConfig();
      
      if (!isValid) {
        await vscode.window.showErrorMessage(
          'Ollama is not running or not accessible. Please start Ollama and ensure it\'s running on localhost:11434'
        );
        return null;
      }
      
      return { type: 'ollama', model: 'llama2:13b' };
    }
    
    // For OpenRouter, we would prompt for API key
    if (provider === 'openrouter') {
      const apiKey = await vscode.window.showInputBox({
        prompt: 'Enter your OpenRouter API key',
        password: true
      });
      
      if (!apiKey) {
        return null;
      }
      
      return { type: 'openrouter', apiKey };
    }
    
    return null;
  }

  private async displayStreaming(
    ticket: RecentTicket,
    runStream: (append: (chunk: string) => void) => Promise<void>
  ): Promise<void> {
    const panel = new StreamingPanel('AI Plan (Streaming)');
    panel.setHeader(`Generating plan for ${ticket.key} - ${ticket.summary}`);

    await runStream((chunk) => panel.appendToken(chunk));
    panel.finish();
  }
}
